FROM apache/airflow:2.7.3

# Hadoop 클라이언트 설치
USER root

# Java 설치 (Hadoop 클라이언트 필요)
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Hadoop 클라이언트 다운로드 및 설치
RUN curl -O https://archive.apache.org/dist/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz && \
    tar -xzf hadoop-3.3.6.tar.gz -C /opt/ && \
    mv /opt/hadoop-3.3.6 /opt/hadoop && \
    rm hadoop-3.3.6.tar.gz

# 환경 변수 설정
ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# Hadoop 설정 파일 복사
COPY ./hadoop/config /opt/hadoop/etc/hadoop/

# 권한 설정
RUN chown -R airflow:airflow /opt/hadoop

# airflow 사용자로 전환
USER airflow

# Python 패키지 설치
COPY requirements/requirements.airflow.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt
